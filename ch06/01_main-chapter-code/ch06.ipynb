{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# Chapter 6: Finetuning for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.1\n",
      "tensorflow version: 2.17.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/chapter-overview.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "946c3e56-b04b-4b0f-b35f-b485ce5b28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to prevent certain cells from being executed twice\n",
    "\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "executed_cells = set()\n",
    "\n",
    "@register_line_cell_magic\n",
    "def run_once(line, cell):\n",
    "    if line not in executed_cells:\n",
    "        get_ipython().run_cell(cell)\n",
    "        executed_cells.add(line)\n",
    "    else:\n",
    "        print(f\"Cell '{line}' has already been executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 Different categories of finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- No code in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- The most common ways to finetune language models are instruction-finetuning and classification finetuning\n",
    "- Instruction-finetuning, depicted below, is the topic of the next chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/instructions.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- Classification finetuning, the topic of this chapter, is a procedure you may already be familiar with if you have a background in machine learning -- it's similar to training a convolutional network to classify handwritten digits, for example\n",
    "- In classification finetuning, we have a specific number of class labels (for example, \"spam\" and \"not spam\") that the model can output\n",
    "- A classification finetuned model can only predict classes it has seen during training (for example, \"spam\" or \"not spam\"), whereas an instruction-finetuned model can usually perform many tasks\n",
    "- We can think of a classification-finetuned model as a very specialized model; in practice, it is much easier to create a specialized model than a generalist model that performs well on many different tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/spam-non-spam.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-1.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- This section prepares the dataset we use for classification finetuning\n",
    "- We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them\n",
    "- First, we download and unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- The dataset is saved as a tab-separated text file, which we can load into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "- (Next to undersampling, there are several other ways to deal with class balances, but they are out of the scope of a book on LLMs; you can find examples and more information in the [`imbalanced-learn` user guide](https://imbalanced-learn.org/stable/user_guide.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Spam: 747\n",
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%%run_once balance_df\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    print(f\"Number of Spam: {num_spam}\")\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "%%run_once label_mapping\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- Let's now define a function that randomly divides the dataset into training, validation, and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 6.3 Creating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- Note that the text messages have different lengths; if we want to combine multiple training examples in a batch, we have to either\n",
    "  1. truncate all messages to the length of the shortest message in the dataset or batch\n",
    "  2. pad all messages to the length of the longest message in the dataset or batch\n",
    "\n",
    "- We choose option 2 and pad all messages to the longest message in the dataset\n",
    "- For that, we use `<|endoftext|>` as a padding token, as discussed in chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/pad-input-sequences.webp?123\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- The `SpamDataset` class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- We also pad the validation and test set to the longest training sequence\n",
    "- Note that validation and test set samples that are longer than the longest training example are being truncated via `encoded_text[:self.max_length]` in the `SpamDataset` code\n",
    "- This behavior is entirely optional, and it would also work well if we set `max_length=None` in both the validation and test set cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders in previous chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/batch.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- As a verification step, we iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- In this section, we initialize the pretrained model we worked with in the previous chapter\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-2.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "7091e401-8442-4f47-a1d9-ecb42a1ef930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- As we can see, the model is not very good at following instructions\n",
    "- This is expected, since it has only been pretrained and not instruction-finetuned (instruction finetuning will be covered in the next chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 Adding a classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/lm-head.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- In this section, we are modifying the pretrained LLM to make it ready for classification finetuning\n",
    "- Let's take a look at the model architecture first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- Above, we can see the architecture we implemented in chapter 4 neatly laid out\n",
    "- The goal is to replace and finetune the output layer\n",
    "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- Then, we replace the output layer (`model.out_head`), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary)\n",
    "- Since we finetune the model for binary classification (predicting 2 classes, \"spam\" and \"not spam\"), we can replace the output layer as shown below, which will be trainable by default\n",
    "- Note that we use `BASE_CONFIG[\"emb_dim\"]` (which is equal to 768 in the `\"gpt2-small (124M)\"` model) to keep the code below more general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- Technically, it's sufficient to only train the output layer\n",
    "- However, as I found in [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models), experiments show that finetuning additional layers can noticeably improve the performance\n",
    "- So, we are also making the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/trainable.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- We can still use this model similar to before in previous chapters\n",
    "- For example, let's feed it some text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- What's different compared to previous chapters is that it now has two output dimensions instead of 50,257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- As discussed in previous chapters, for each input token, there's one output vector\n",
    "- Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/input-and-output.webp\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- In chapter 3, we discussed the attention mechanism, which connects each input token to each other input token\n",
    "- In chapter 3, we then also introduced the causal attention mask that is used in GPT-like models; this causal mask lets a current token only attend to the current and previous token positions\n",
    "- Based on this causal attention mechanism, the 4th (last) token contains the most information among all tokens because it's the only token that includes information about all other tokens\n",
    "- Hence, we are particularly interested in this last token, which we will finetune for the spam classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/attention-mask.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 6.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-3.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/class-argmax.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- Note that the softmax function is optional here, as explained in chapter 5, because the largest outputs correspond to the largest probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset\n",
    "- To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- Let's apply the function to calculate the classification accuracies for the different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- As we can see, the prediction accuracies are not very good, since we haven't finetuned the model, yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- Before we can start finetuning (/training), we first have to define the loss function we want to optimize during training\n",
    "- The goal is to maximize the spam classification accuracy of the model; however, classification accuracy is not a differentiable function\n",
    "- Hence, instead, we minimize the cross-entropy loss as a proxy for maximizing the classification accuracy (you can learn more about this topic in lecture 8 of my freely available [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) class)\n",
    "\n",
    "- The `calc_loss_batch` function is the same here as in chapter 5, except that we are only interested in optimizing the last token `model(input_batch)[:, -1, :]` instead of all tokens `model(input_batch)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "The `calc_loss_loader` is exactly the same as in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- In the next section, we train the model to improve the loss values and consequently the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- In this section, we define and use the training function to improve the classification accuracy of the model\n",
    "- The `train_classifier_simple` function below is practically the same as the `train_model_simple` function we used for pretraining the model in chapter 5\n",
    "- The only two differences are that we now \n",
    "  1. track the number of training examples seen (`examples_seen`) instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/training-loop.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- The `evaluate_model` function used in the `train_classifier_simple` is the same as the one we used in chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- The training takes about 5 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 5.68 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- Similar to chapter 5, we use matplotlib to plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- Above, based on the downward slope, we see that the model learns well\n",
    "- Furthermore, the fact that the training and validation loss are very close indicates that the model does not tend to overfit the training data\n",
    "- Similarly, we can plot the accuracy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- Based on the accuracy plot above, we can see that the model achieves a relatively high training and validation accuracy after epochs 4 and 5\n",
    "- However, we have to keep in mind that we specified `eval_iter=5` in the training function earlier, which means that we only estimated the training and validation set performances\n",
    "- We can compute the training, validation, and test set performances over the complete dataset as follows below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- We can see that the training and validation set performances are practically identical\n",
    "- However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate\n",
    "- This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 6.8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-4.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- Finally, let's use the finetuned GPT model in action\n",
    "- The `classify_review` function below implements the data preprocessing steps similar to the `SpamDataset` we implemented earlier\n",
    "- Then, the function returns the predicted integer class label from the model and returns the corresponding class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- Let's try it out on a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- Finally, let's save the model in case we want to reuse the model later without having to train it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- Then, in a new session, we could load the model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## Summary and takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- See the [./gpt_class_finetune.py](./gpt_class_finetune.py) script, a self-contained script for classification finetuning\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)\n",
    "- In addition, interested readers can find an introduction to parameter-efficient training with low-rank adaptation (LoRA) in [appendix E](../../appendix-E)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
