{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff",
   "metadata": {
    "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff"
   },
   "source": [
    "# Appendix E: Parameter-efficient Finetuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "316166b4-027a-4756-e9b4-fe88ae75dd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.1\n",
      "tensorflow version: 2.17.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21532056-0ef4-4c98-82c7-e91f61c6485e",
   "metadata": {
    "id": "21532056-0ef4-4c98-82c7-e91f61c6485e"
   },
   "source": [
    "## E.1 Introduction to LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edc999-3d91-4a1c-a157-9d056392e8d8",
   "metadata": {
    "id": "66edc999-3d91-4a1c-a157-9d056392e8d8"
   },
   "source": [
    "- No code in this section\n",
    "- Low-rank adaptation (LoRA) is a machine learning technique that modifies a pretrained model to better suit a specific, often smaller, dataset by adjusting only a small, low-rank subset of the model's parameters\n",
    "- This approach is important because it allows for efficient finetuning of large models on task-specific data, significantly reducing the computational cost and time required for finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1",
   "metadata": {
    "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1"
   },
   "source": [
    "- Suppose we have a large weight matrix $W$ for a given layer\n",
    "- During backpropagation, we learn a $\\Delta W$ matrix, which contains information on how much we want to update the original weights to minimize the loss function during training\n",
    "- In regular training and finetuning, the weight update is defined as follows:\n",
    "\n",
    "$$W_{\\text{updated}} = W + \\Delta W$$\n",
    "\n",
    "- The LoRA method proposed by [Hu et al.](https://arxiv.org/abs/2106.09685) offers a more efficient alternative to computing the weight updates $\\Delta W$ by learning an approximation of it, $\\Delta W \\approx AB$.\n",
    "- In other words, in LoRA, we have the following, where $A$ and $B$ are two small weight matrices:\n",
    "\n",
    "$$W_{\\text{updated}} = W + AB$$\n",
    "\n",
    "- The figure below illustrates these formulas for full finetuning and LoRA side by side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b",
   "metadata": {
    "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-1.webp\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc",
   "metadata": {
    "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc"
   },
   "source": [
    "- If you paid close attention, the full finetuning and LoRA depictions in the figure above look slightly different from the formulas I have shown earlier\n",
    "- That's due to the distributive law of matrix multiplication: we don't have to add the weights with the updated weights but can keep them separate\n",
    "- For instance, if $x$ is the input data, then we can write the following for regular finetuning:\n",
    "\n",
    "$$x (W+\\Delta W) = x W + x \\Delta W$$\n",
    "\n",
    "- Similarly, we can write the following for LoRA:\n",
    "\n",
    "$$x (W+A B) = x W + x A B$$\n",
    "\n",
    "- The fact that we can keep the LoRA weight matrices separate makes LoRA especially attractive\n",
    "- In practice, this means that we don't have to modify the weights of the pretrained model at all, as we can apply the LoRA matrices on the fly\n",
    "- After setting up the dataset and loading the model, we will implement LoRA in the code to make these concepts less abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## E.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c64df-4431-4d27-834d-2bb38a01fc02",
   "metadata": {
    "id": "669c64df-4431-4d27-834d-2bb38a01fc02"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the dataset\n",
    "- Instead of repeating this code, one could open and run the chapter 6 notebook and then insert the LoRA code from section E.4 there\n",
    "- (The LoRA code was originally the last section of chapter 6 but was moved to the appendix due to the length of chapter 6)\n",
    "- In a similar fashion, we could also apply LoRA to the models in chapter 7 for instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "a67a7afe-b401-4463-c731-87025d20f72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from previous_chapters import (\n",
    "    download_and_unzip_spam_data,\n",
    "    create_balanced_dataset,\n",
    "    random_split\n",
    ")\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken\n",
    "from previous_chapters import SpamDataset\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- As a verification step, we iterate through the data loaders and check that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "2ae34de1-dd01-4f99-d2c8-ba4dca400754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "4d19ed61-cf7a-4ec4-b822-c847dd1c5d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604",
   "metadata": {
    "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604"
   },
   "source": [
    "## E.3 Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1",
   "metadata": {
    "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
    "outputId": "b8c9b125-bb52-45d3-8071-fa5054dbf5a9"
   },
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "# 因为之前下载了，可以直接加载本地的\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, \n",
    "                                          models_dir=\"/Users/kyleee/code/project/LLMs-from-scratch/ch06/01_main-chapter-code/gpt2\", \n",
    "                                          local_only=True)\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252614cd-7ce6-4908-83e6-3761f519904e",
   "metadata": {
    "id": "252614cd-7ce6-4908-83e6-3761f519904e"
   },
   "source": [
    "- To ensure that the model was loaded corrected, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
    "outputId": "28ccbca5-8de9-41a0-c093-da00fcbaa91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174b31b-1ab5-4115-b01c-245369da5af3",
   "metadata": {
    "id": "8174b31b-1ab5-4115-b01c-245369da5af3"
   },
   "source": [
    "- Then, we prepare the model for classification finetuning similar to chapter 6, where we replace the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e255ce91-d73a-4854-90a4-95804928eb16",
   "metadata": {
    "id": "e255ce91-d73a-4854-90a4-95804928eb16"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e6f057-1383-4ece-8444-0a88e71ac75d",
   "metadata": {
    "id": "02e6f057-1383-4ece-8444-0a88e71ac75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 1.2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "model.to(device);  # no assignment model = model.to(device) necessary for nn.Module classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe",
   "metadata": {
    "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe"
   },
   "source": [
    "- Lastly, let's calculate the initial classification accuracy of the non-finetuned model (we expect this to be around 50%, which means that the model is not able to distinguish between spam and non-spam messages yet reliably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
    "outputId": "74848515-5a49-4125-fecb-9f4bac23f812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import calc_accuracy_loader\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b",
   "metadata": {
    "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b"
   },
   "source": [
    "## E.4 Parameter-efficient finetuning with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4a82-61ef-4d0a-9858-8988e844f12c",
   "metadata": {
    "id": "652a4a82-61ef-4d0a-9858-8988e844f12c"
   },
   "source": [
    "- We begin by initializing a LoRALayer that creates the matrices $A$ and $B$, along with the `alpha` scaling hyperparameter and the `rank` ($r$) hyperparameters\n",
    "- This layer can accept an input and compute the corresponding output, as illustrated in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-2.webp\" width=\"200px\">\n",
    "\n",
    "In code, this LoRA layer depicted in the figure above looks like as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ds9ywjMwvIW",
   "metadata": {
    "id": "2ds9ywjMwvIW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  # similar to standard weight initialization\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21faa8-0614-4257-93cd-68952193e14a",
   "metadata": {
    "id": "ad21faa8-0614-4257-93cd-68952193e14a"
   },
   "source": [
    "- In the code above, `rank` is a hyperparameter that controls the inner dimension of the matrices $A$ and $B$\n",
    "- In other words, this parameter controls the number of additional parameters introduced by LoRA and is a key factor in determining the balance between model adaptability and parameter efficiency\n",
    "- The second hyperparameter, `alpha`, is a scaling hyperparameter applied to the output of the low-rank adaptation\n",
    "- It essentially controls the extent to which the adapted layer's output is allowed to influence the original output of the layer being adapted\n",
    "- This can be seen as a way to regulate the impact of the low-rank adaptation on the layer's output\n",
    "- So far, the `LoRALayer` class we implemented above allows us to transform the layer inputs $x$\n",
    "- However, in LoRA, we are usually interested in replacing existing `Linear` layers so that the weight update is applied to the existing pretrained weights, as shown in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-3.webp\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f",
   "metadata": {
    "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f"
   },
   "source": [
    "- To incorporate the original `Linear` layer weights as shown in the figure above, we implement a `LinearWithLoRA` layer below that uses the previously implemented LoRALayer and can be used to replace existing `Linear` layers in a neural network, for example, the self-attention module or feed forward modules in an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127d3a64-8359-4b21-b056-78d58cc75fe8",
   "metadata": {
    "id": "127d3a64-8359-4b21-b056-78d58cc75fe8"
   },
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1145a90-35ff-462c-820b-15483fa5b051",
   "metadata": {
    "id": "e1145a90-35ff-462c-820b-15483fa5b051"
   },
   "source": [
    "- Note that since we initialize the weight matrix $B$ (`self.B` in `LoRALayer`) with zero values in the LoRA layer, the matrix multiplication between $A$ and $B$ results in a matrix consisting of 0's and doesn't affect the original weights (since adding 0 to the original weights does not modify them)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d",
   "metadata": {
    "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d"
   },
   "source": [
    "- To try LoRA on the GPT model we defined earlier, we define a `replace_linear_with_lora` function to replace all `Linear` layers in the model with the new `LinearWithLoRA` layers\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-4.webp\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "WlQZ8ygqzN_g",
   "metadata": {
    "id": "WlQZ8ygqzN_g"
   },
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            # Replace the Linear layer with LinearWithLoRA\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            # Recursively apply the same function to child modules\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2",
   "metadata": {
    "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2"
   },
   "source": [
    "- We then freeze the original model parameter and use the `replace_linear_with_lora` to replace the said `Linear` layers using the code below\n",
    "- This will replace the `Linear` layers in the LLM with `LinearWithLoRA` layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
    "outputId": "fd4c208f-854a-4701-d9d3-9d73af733364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mLk_fPq0yz_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLk_fPq0yz_u",
    "outputId": "0a93b8fc-05d7-4ace-ee47-e2fc6bdd7d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9",
   "metadata": {
    "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9"
   },
   "source": [
    "- As we can see, we reduced the number of trainable parameters by almost 50x when using LoRA\n",
    "- Let's now double-check whether the layers have been modified as intended by printing the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
    "outputId": "acff8eca-3775-45a2-b62d-032a986ef037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55",
   "metadata": {
    "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55"
   },
   "source": [
    "- Based on the model architecture above, we can see that the model now contains our new `LinearWithLoRA` layers\n",
    "- Also, since we initialized matrix $B$ with 0's, we expect the initial model performance to be unchanged compared to before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "DAlrb_I00VEU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAlrb_I00VEU",
    "outputId": "3da44ac4-230b-4358-d996-30b63f0d962a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101",
   "metadata": {
    "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101"
   },
   "source": [
    "- Let's now get to the interesting part and finetune the model by reusing the training function from chapter 6\n",
    "- The training takes about 15 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wCParRvr0eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCParRvr0eff",
    "outputId": "ce910a9c-ee89-48bb-bfa6-49c6aee1e450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.820, Val loss 3.462\n",
      "Ep 1 (Step 000050): Train loss 0.396, Val loss 0.364\n",
      "Ep 1 (Step 000100): Train loss 0.111, Val loss 0.229\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150): Train loss 0.135, Val loss 0.073\n",
      "Ep 2 (Step 000200): Train loss 0.008, Val loss 0.051\n",
      "Ep 2 (Step 000250): Train loss 0.022, Val loss 0.178\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300): Train loss 0.082, Val loss 0.053\n",
      "Ep 3 (Step 000350): Train loss 0.019, Val loss 0.130\n",
      "Training accuracy: 100.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.004, Val loss 0.142\n",
      "Ep 4 (Step 000450): Train loss 0.005, Val loss 0.023\n",
      "Ep 4 (Step 000500): Train loss 0.000, Val loss 0.119\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 5 (Step 000550): Train loss 0.009, Val loss 0.183\n",
      "Ep 5 (Step 000600): Train loss 0.017, Val loss 0.015\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 10.78 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from previous_chapters import train_classifier_simple\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c",
   "metadata": {
    "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c"
   },
   "source": [
    "- Finally, let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bawWGijA0iF3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "bawWGijA0iF3",
    "outputId": "af70782a-d605-4376-fa6c-d33b38979cfa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOGElEQVR4nO3dd3xUVfr48c+dmdRJJSGNFEACCKRAAhhAREGKyoroqvwQwbooVXQtIFVdLIuiX1ZWUVFXJYiIyyoiRZoCEkogkBCQlgAptHQySWbu749JJhlCSULCTJLn/fK+ZubMufc+c4jzzDn33HsVVVVVhBBCCGGXNLYOQAghhBBXJolaCCGEsGOSqIUQQgg7JolaCCGEsGOSqIUQQgg7JolaCCGEsGOSqIUQQgg7JolaCCGEsGOSqIUQQgg7JolaCGGlX79+TJ482dZhCCHKSaIWop6NGTMGRVGqLYMHD7Z1aEKIRkhn6wCEaIoGDx7M4sWLrcqcnJxsFI0QojGTHrUQDcDJyYmAgACrxdvbG4CNGzfi6OjIli1bLPXnzZuHr68vGRkZAKxevZo+ffrg5eWFj48P99xzD0eOHLHUP378OIqi8O2333Lrrbfi4uJC9+7dOXToEAkJCcTGxuLm5sbgwYM5c+aMZb0xY8YwbNgwZs+ejZ+fHx4eHvztb3+jpKTkip+lpKSEF198kVatWqHX6+nZsycbN260vH/ixAmGDh2Kt7c3er2ezp07s2rVqitu78MPPyQ8PBxnZ2f8/f154IEHLO+pqsrbb79N27ZtcXFxISoqiu+++85q/eTkZO666y7c3Nzw9/dn1KhRnD171vJ+v379mDhxIi+++CItWrQgICCAWbNmXTEeIeydJGohbrCKY8CjRo0iNzeXvXv3Mm3aNBYtWkRgYCAAhYWFTJkyhYSEBNavX49Go+G+++7DZDJZbWvmzJm8+uqr7N69G51Ox4gRI3jxxRd5//332bJlC0eOHGHGjBlW66xfv56UlBQ2bNjAkiVLWLFiBbNnz75ivI899hi///478fHx7Nu3j7/+9a8MHjyYw4cPAzBu3DgMBgObN28mKSmJt956Czc3t8tua+fOnUycOJE5c+aQmprK6tWr6du3r+X9V199lcWLF7Nw4UIOHDjAc889xyOPPMKmTZsAyMjI4LbbbiM6OpqdO3eyevVqsrKyePDBB63288UXX6DX6/njjz94++23mTNnDmvXrq3hv5AQdkYVQtSr0aNHq1qtVtXr9VbLnDlzLHUMBoPatWtX9cEHH1Q7d+6sPvnkk1fdZnZ2tgqoSUlJqqqq6rFjx1RA/eSTTyx1lixZogLq+vXrLWVz585VO3ToYBVbixYt1MLCQkvZwoULVTc3N9VoNKqqqqq33XabOmnSJFVVVfXPP/9UFUVRT506ZRVP//791VdeeUVVVVWNiIhQZ82aVaO2Wb58uerh4aHm5eVVe6+goEB1dnZWt27dalX+xBNPqCNGjFBVVVWnT5+uDhw40Or99PR0FVBTU1Mt8ffp08eqTvfu3dWXXnqpRjEKYW/kGLUQDeD2229n4cKFVmUtWrSwPHd0dOSrr74iMjKSsLAw5s+fb1X3yJEjTJ8+ne3bt3P27FlLTzotLY0uXbpY6kVGRlqe+/v7AxAREWFVlp2dbbXtqKgoXF1dLa/j4uIoKCggPT2dsLAwq7q7d+9GVVXat29vVW4wGPDx8QFg4sSJPPPMM6xZs4YBAwZw//33W8VV1Z133klYWBht27Zl8ODBDB48mPvuuw9XV1eSk5MpLi7mzjvvtFqnpKSErl27ArBr1y42bNhw2R77kSNHLHFeuv/AwMBq7SBEYyGJWogGoNfradeu3VXrbN26FYDz589z/vx59Hq95b2hQ4cSEhLCokWLCAoKwmQy0aVLl2rHkh0cHCzPFUW5bNmlw+VXUrF+VSaTCa1Wy65du9BqtVbvVSTLJ598kkGDBvHTTz+xZs0a5s6dy7x585gwYUK17bm7u7N79242btzImjVrmDFjBrNmzSIhIcES508//USrVq2s1quYiGcymRg6dChvvfVWtW1XHDa4tA0qPltN20EIeyOJWggbOHLkCM899xyLFi3i22+/5dFHH7Uciz537hwpKSl89NFH3HrrrQD89ttv9bbvvXv3cvHiRVxcXADYvn07bm5uBAcHV6vbtWtXjEYj2dnZllguJyQkhLFjxzJ27FheeeUVFi1adNlEDaDT6RgwYAADBgxg5syZeHl58euvv3LnnXfi5OREWloat91222XX7datG8uXL6d169bodPL1JZoH+UsXogEYDAYyMzOtynQ6Hb6+vhiNRkaNGsXAgQN57LHHGDJkCBEREcybN4+///3veHt74+Pjw8cff0xgYCBpaWm8/PLL9RZbSUkJTzzxBK+++ionTpxg5syZjB8/Ho2m+tzS9u3bM3LkSB599FHmzZtH165dOXv2LL/++isRERHcddddTJ48mSFDhtC+fXsuXLjAr7/+ys0333zZff/4448cPXqUvn374u3tzapVqzCZTHTo0AF3d3deeOEFnnvuOUwmE3369CEvL4+tW7fi5ubG6NGjGTduHIsWLWLEiBH8/e9/x9fXlz///JP4+HgWLVpUrdcvRFMgiVqIBrB69WqroViADh06cPDgQd544w2OHz/O//73PwACAgL45JNPePDBB7nzzjuJjo4mPj6eiRMn0qVLFzp06MAHH3xAv3796iW2/v37Ex4eTt++fTEYDDz88MNXPX1p8eLFvP766zz//POcOnUKHx8f4uLiuOuuuwAwGo2MGzeOkydP4uHhweDBg3nvvfcuuy0vLy++//57Zs2aRXFxMeHh4SxZsoTOnTsD8Nprr+Hn58fcuXM5evQoXl5edOvWjalTpwIQFBTE77//zksvvcSgQYMwGAyEhYUxePDgy/7QEKIpUFRVVW0dhBDixhgzZgw5OTn88MMPtg5FCFFD8hNUCCGEsGOSqIUQQgg7JkPfQgghhB2THrUQQghhxyRRCyGEEHZMErUQQghhxyRRl/vwww9p06YNzs7OxMTEWN2CsKnavHkzQ4cOJSgoCEVRqp2yo6oqs2bNIigoCBcXF/r168eBAwes6hgMBiZMmICvry96vZ6//OUvnDx50qrOhQsXGDVqFJ6ennh6ejJq1ChycnIa+NPVr7lz59K9e3fc3d3x8/Nj2LBhpKamWtWR9qq0cOFCIiMj8fDwwMPDg7i4OH7++WfL+9JWVzZ37lwURWHy5MmWMmmvSrNmzUJRFKslICDA8n6TbCtb3Q3EnsTHx6sODg7qokWL1OTkZHXSpEmqXq9XT5w4YevQGtSqVavUadOmqcuXL1cBdcWKFVbvv/nmm6q7u7u6fPlyNSkpSX3ooYfUwMBAqzsfjR07Vm3VqpW6du1adffu3ertt9+uRkVFqWVlZZY6gwcPVrt06aJu3bpV3bp1q9qlSxf1nnvuuVEfs14MGjRIXbx4sbp//341MTFRvfvuu9XQ0FC1oKDAUkfaq9LKlSvVn376SU1NTVVTU1PVqVOnqg4ODur+/ftVVZW2upIdO3aorVu3ViMjIy13MFNVaa+qZs6cqXbu3FnNyMiwLNnZ2Zb3m2JbSaJWVbVHjx7q2LFjrco6duyovvzyyzaK6Ma7NFGbTCY1ICBAffPNNy1lxcXFqqenp/rvf/9bVVVVzcnJUR0cHNT4+HhLnVOnTqkajUZdvXq1qqqqmpycrALq9u3bLXW2bdumAurBgwcb+FM1nIrbTm7atElVVWmvmvD29lY/+eQTaasryM/PV8PDw9W1a9da3WpU2svazJkz1aioqMu+11TbqtkPfZeUlLBr1y4GDhxoVT5w4EDL3Y2ao2PHjpGZmWnVLk5OTtx2222Wdtm1axelpaVWdYKCgujSpYulzrZt2/D09KRnz56WOrfccguenp6Nun1zc3OByltXSntdmdFoJD4+nsLCQuLi4qStrmDcuHHcfffdDBgwwKpc2qu6w4cPExQURJs2bXj44Yc5evQo0HTbqtlf6/vs2bMYjUbLvXwr+Pv7V7upQnNS8dkv1y4nTpyw1HF0dMTb27tanYr1MzMz8fPzq7Z9Pz+/Rtu+qqoyZcoU+vTpY7k3tLRXdUlJScTFxVFcXIybmxsrVqygU6dOli86aatK8fHx7N69m4SEhGrvyd+WtZ49e/Lll1/Svn17srKyeP311+nVqxcHDhxosm3V7BN1hUvvxauq6mXvz9vc1KVdLq1zufqNuX3Hjx/Pvn37LnvrSWmvSh06dCAxMZGcnByWL1/O6NGj2bRpk+V9aSuz9PR0Jk2axJo1a3B2dr5iPWkvsyFDhlieR0REEBcXx0033cQXX3zBLbfcAjS9tmr2Q9++vr5otdpqv5Kys7Or/SprTipmUV6tXQICAigpKeHChQtXrZOVlVVt+2fOnGmU7TthwgRWrlzJhg0brO7fLO1VnaOjI+3atSM2Npa5c+cSFRXF+++/L211iV27dpGdnU1MTAw6nQ6dTsemTZv44IMP0Ol0ls8i7XV5er2eiIgIDh8+3GT/tpp9onZ0dCQmJoa1a9dala9du5ZevXrZKCrba9OmDQEBAVbtUlJSwqZNmyztEhMTg4ODg1WdjIwM9u/fb6kTFxdHbm4uO3bssNT5448/yM3NbVTtq6oq48eP5/vvv+fXX3+lTZs2Vu9Le12bqqoYDAZpq0v079+fpKQkEhMTLUtsbCwjR44kMTGRtm3bSntdhcFgICUlhcDAwKb7t3WDJ6/ZpYrTsz799FM1OTlZnTx5sqrX69Xjx4/bOrQGlZ+fr+7Zs0fds2ePCqjvvvuuumfPHstpaW+++abq6empfv/992pSUpI6YsSIy57mEBwcrK5bt07dvXu3escdd1z2NIfIyEh127Zt6rZt29SIiIhGd0rIM888o3p6eqobN260Oi2kqKjIUkfaq9Irr7yibt68WT127Ji6b98+derUqapGo1HXrFmjqqq01bVUnfWtqtJeVT3//PPqxo0b1aNHj6rbt29X77nnHtXd3d3yfd0U20oSdbl//etfalhYmOro6Kh269bNctpNU7ZhwwYVqLaMHj1aVVXzqQ4zZ85UAwICVCcnJ7Vv375qUlKS1TYuXryojh8/Xm3RooXq4uKi3nPPPWpaWppVnXPnzqkjR45U3d3dVXd3d3XkyJHqhQsXbtCnrB+XaydAXbx4saWOtFelxx9/3PL/U8uWLdX+/ftbkrSqSltdy6WJWtqrUsV50Q4ODmpQUJA6fPhw9cCBA5b3m2Jbyd2zhBBCCDvW7I9RCyGEEPZMErUQQghhxyRRCyGEEHZMErUQQghhxyRRCyGEEHZMErUQQghhxyRRV2EwGJg1axYGg8HWodg9aavakfaqOWmr2pH2qrnG2lZ2cx713LlzmTp1KpMmTWL+/Pk2iSEvLw9PT09yc3Px8PCwSQyNhbRV7Uh71Zy0Ve1Ie9VcY20ru+hRJyQk8PHHHxMZGWnrUIQQQgi7YvNEXVBQwMiRI1m0aFG1+4MKIYQQzZ3N70c9btw47r77bgYMGMDrr79eq3XLysrYs2cP/v7+aDTX/5sjPz8fgFOnTpGXl3fd22vKpK1qR9qr5qStakfaq+bsqa1MJhNZWVl07doVne7qqdimiTo+Pp7du3eTkJBQo/oGg8FqEsCuXbu444476j2uTp061fs2myppq9qR9qo5aavakfaqOXtqqx07dtC9e/er1rFZok5PT2fSpEmsWbMGZ2fnGq0zd+5cZs+eXa18x44dBAYG1neIQgghRIPIyMigR48e+Pv7X7OuzWZ9//DDD9x3331otVpLmdFoRFEUNBoNBoPB6j2o3qM+deoUnTp1Ij09neDg4BsWuxBCCHE9Tp48SUhISI3yl8161P379ycpKcmq7LHHHqNjx4689NJL1ZI0gJOTE05OTpbXtj7GIIQQQjQ0myVqd3d3unTpYlWm1+vx8fGpVi6EEEI0VzY/PUsIIYQQV2bz07Oq2rhxo61DEEI0c0ajkdLSUluHIRo5BweHyx7CrQu7StS2VGgoY296DmUmlb7tW9o6HCHEDaaqKpmZmeTk5Ng6FNFEeHl5ERAQgKIo17UdSdTl1h/MZuKSPUQGe0qiFqIZqkjSfn5+uLq6XveXq2i+VFWlqKiI7OxsgOs+fVgSdbmuIV4ApGTkUVxqxNmhfoYshBD2z2g0WpK0j4+PrcMRTYCLiwsA2dnZ+Pn5XdcwuEwmKxfs7YKP3pFSo8qB03LalxDNScUxaVdXVxtHIpqSir+n653zIIm6nKIodA31AmBP2gXbBiOEsAkZ7hb1qb7+niRRVxFdPvydmJ5j0ziEEEKICpKoq4gOMd9mUxK1EKI569evH5MnT65x/ePHj6MoComJiQ0WE5hP4VUUpdnNzJfJZFVEhniiKHDywkXOFhjwdXO69kpCCGEj1xpaHT16NJ9//nmtt/v999/j4OBQ4/ohISFkZGTg6+tb632Ja5NEXYWHswM3tXTjz+wCEtNyGNDp2nc1EUIIW8nIyLA8X7p0KTNmzCA1NdVSVjHzuEJpaWmNEnCLFi1qFYdWqyUgIKBW64iak6HvS8hxaiFEYxEQEGBZPD09URTF8rq4uBgvLy++/fZb+vXrh7OzM1999RXnzp1jxIgRBAcH4+rqSkREBEuWLLHa7qVD361bt+Yf//gHjz/+OO7u7oSGhvLxxx9b3r906LtiiHr9+vXExsbi6upKr169rH5EALz++uv4+fnh7u7Ok08+ycsvv0x0dHSt2mD58uV07twZJycnWrduzbx586ze//DDDwkPD8fZ2Rl/f38eeOABy3vfffcdERERuLi44OPjw4ABAygsLKzV/m8ESdSXkEQthIDyi1aUlNlkqc+7D7/00ktMnDiRlJQUBg0aRHFxMTExMfz444/s37+fp59+mlGjRvHHH39cdTvz5s0jNjaWPXv28Oyzz/LMM89w8ODBq64zbdo05s2bx86dO9HpdDz++OOW977++mveeOMN3nrrLXbt2kVoaCgLFy6s1WfbtWsXDz74IA8//DBJSUnMmjWL6dOnW4b7d+7cycSJE5kzZw6pqamsXr2avn37AubRiBEjRvD444+TkpLCxo0bGT58eL22fX2Roe9LVJyitTc9B5NJRaOR0zWEaI4ulhrpNOMXm+w7ec4gXB3r5+t58uTJDB8+3KrshRdesDyfMGECq1evZtmyZfTs2fOK27nrrrt49tlnAXPyf++999i4cSMdO3a84jpvvPEGt912GwAvv/wyd999N8XFxTg7O/N///d/PPHEEzz22GMAzJgxgzVr1lBQUFDjz/buu+/Sv39/pk+fDkD79u1JTk7mnXfeYcyYMaSlpaHX67nnnntwd3cnLCyMrl27AuZEXVZWxvDhwwkLCwMgIiKixvu+kaRHfYkO/u64OGjJN5Rx5EzN/2CEEMIexcbGWr02Go288cYbREZG4uPjg5ubG2vWrCEtLe2q24mMjLQ8rxhir7hEZk3WqbiMZsU6qamp9OjRw6r+pa+vJSUlhd69e1uV9e7dm8OHD2M0GrnzzjsJCwujbdu2jBo1iq+//pqioiIAoqKi6N+/PxEREfz1r39l0aJFXLhgn9fQkB71JXRaDRGtPNlx/Dx70nMI93e3dUhCCBtwcdCSPGeQzfZdX/R6vdXrefPm8d577zF//nwiIiLQ6/VMnjyZkpKSq27n0kloiqJgMplqvE7FDPWq61w6a722w86qql51G+7u7uzevZuNGzeyZs0aZsyYwaxZs0hISMDLy4u1a9eydetW1qxZw//93/8xbdo0/vjjD9q0aVOrOBqa9KgvI7p8+FuOUwvRfCmKgqujziZLQ14hbcuWLdx777088sgjREVF0bZtWw4fPtxg+7uSDh06sGPHDquynTt31mobnTp14rfffrMq27p1K+3bt7dcW1un0zFgwADefvtt9u3bx/Hjx/n1118B879x7969mT17Nnv27MHR0ZEVK1Zcx6dqGNKjvgzLhLK0HJvGIYQQ9a1du3YsX76crVu34u3tzbvvvktmZiY333zzDY1jwoQJPPXUU8TGxtKrVy+WLl3Kvn37aNu2bY238fzzz9O9e3dee+01HnroIbZt28aCBQv48MMPAfjxxx85evQoffv2xdvbm1WrVmEymejQoQN//PEH69evZ+DAgfj5+fHHH39w5syZG94ONSGJ+jIqEnVqVj4XS4y4OMqdtIQQTcP06dM5duwYgwYNwtXVlaeffpphw4aRm5t7Q+MYOXIkR48e5YUXXqC4uJgHH3yQMWPGVOtlX023bt349ttvmTFjBq+99hqBgYHMmTOHMWPGAOb7QX///ffMmjWL4uJiwsPDWbJkCZ07dyYlJYXNmzczf/588vLyCAsLY968eQwZMqSBPnHdKao9zkWvoZMnTxISEkJ6ejrBwcHXt7EyA5z4Hc7+idrjKXr+Yz3Z+Qa+/VscPdrU7uR/IUTjUlxczLFjx2jTpg3Ozs62DqfZuvPOOwkICOA///mPrUOpF1f7u6pN/pIedYWLOfCf+wAFJfJBokO8WJOcRWL6BUnUQghRz4qKivj3v//NoEGD0Gq1LFmyhHXr1rF27Vpbh2Z3ZDJZBXd/aNEWUCF9B11D5QYdQgjRUBRFYdWqVdx6663ExMTwv//9j+XLlzNgwABbh2Z3pEddVWgvOH8U0rYS3SYGgD0yoUwIIeqdi4sL69ats3UYjYL0qKsKizM/nthGZLAnGgUycovJyiu2bVxCCCGaLUnUVYWWJ+rTu9FrymhffrET6VULIYSwFUnUVbVoC3o/MJbAqV1ygw4hhBA2J4m6KkWpHP5O21olUdvn9V+FEEI0fZKoLxXay/x4YpvlUqJJJ3Mxmhrt6eZCCCEaMUnUl6roUafvINzXFb2jlsISI4ez820blxBCiGZJEvWl/LuAkweU5KM9c4DIYC9ArvsthGi6+vXrx+TJky2vW7duzfz586+6jqIo/PDDD9e97/raztXMmjWL6OjoBt1HQ5JEfSmNFkLK74laZfhbZn4LIezN0KFDr3iBkG3btqEoCrt37671dhMSEnj66aevNzwrV0qWGRkZdnl9bXsiifpyQi83oSzHZuEIIcTlPPHEE/z666+cOHGi2nufffYZ0dHRdOvWrdbbbdmyJa6urvUR4jUFBATg5OR0Q/bVWEmivpw2t0Hb2yGsN13LE/Wh7HwKDGW2jUsIIaq455578PPz4/PPP7cqLyoqYunSpTzxxBOcO3eOESNGEBwcjKurKxERESxZsuSq27106Pvw4cP07dsXZ2dnOnXqdNnrcb/00ku0b98eV1dX2rZty/Tp0yktLQXg888/Z/bs2ezduxdFUVAUxRLzpUPfSUlJ3HHHHbi4uODj48PTTz9NQUGB5f0xY8YwbNgw/vnPfxIYGIiPjw/jxo2z7KsmTCYTc+bMITg4GCcnJ6Kjo1m9erXl/ZKSEsaPH09gYCDOzs60bt2auXPnWt6fNWsWoaGhODk5ERQUxMSJE2u877qQS4heTkh3ePQHAPyAIE9nTucWs+9kDr1u8rVpaEKIG6yksPbraJ1AW/71aiwDowEUDTi4XHu7jvoa70an0/Hoo4/y+eefM2PGDBRFAWDZsmWUlJQwcuRIioqKiImJ4aWXXsLDw4OffvqJUaNG0bZtW3r27HnNfZhMJoYPH46vry/bt28nLy/P6nh2BXd3dz7//HOCgoJISkriqaeewt3dnRdffJGHHnqI/fv3s3r1astlQz09Patto6ioiMGDB3PLLbeQkJBAdnY2Tz75JOPHj7f6MbJhwwYCAwPZsGEDf/75Jw899BDR0dE89dRTNWq3999/n3nz5vHRRx/RtWtXPvvsM/7yl79w4MABwsPD+eCDD1i5ciXffvstoaGhpKenk56eDsB3333He++9R3x8PJ07dyYzM5O9e/fWaL91JYm6BqJDvTidlEliuiRqIZqdfwTVfp2/fg6d7zM/P/g/WDYGwvrAYz9V1pkfAUXnqq87q3b3hX788cd555132LhxI7fffjtgHvYePnw43t7eeHt788ILL1jqT5gwgdWrV7Ns2bIaJep169aRkpLC8ePHLbdj/Mc//lHtuPKrr75qed66dWuef/55li5dyosvvoiLiwtubm7odDoCAgKuuK+vv/6aixcv8uWXX6LXm3+wLFiwgKFDh/LWW2/h7+8PgLe3NwsWLECr1dKxY0fuvvtu1q9fX+NE/c9//pOXXnqJhx9+GIC33nqLDRs2MH/+fP71r3+RlpZGeHg4ffr0QVEUwsLCLOumpaUREBDAgAEDcHBwIDQ0lB49etRov3UlQ99XU5ANp3ZXHqeWCWVCCDvTsWNHevXqxWeffQbAkSNH2LJlC48//jgARqORN954g8jISHx8fHBzc2PNmjWkpaXVaPspKSmEhoZa3TM5Li6uWr3vvvuOPn36EBAQgJubG9OnT6/xPqruKyoqypKkAXr37o3JZCI1NdVS1rlzZ7RareV1YGAg2dnZNdpHXl4ep0+fpnfv3lblvXv3JiUlBTAPrycmJtKhQwcmTpzImjVrLPX++te/cvHiRdq2bctTTz3FihUrKCtr2MOiNu1RL1y4kIULF3L8+HHA3PgzZsywjxmAxzbDF0PBuw1d7/0VgD3pOaiqahleEkI0A1NP134dbZXJUR2HmrehXNIvmpx0fXFV8cQTTzB+/Hj+9a9/sXjxYsLCwujfvz8A8+bN47333mP+/PlERESg1+uZPHkyJSUlNdq2qla/2NOl34Hbt2/n4YcfZvbs2QwaNAhPT0/i4+OZN29erT7H1b5fq5Y7ODhUe89kMtVqX5fup+q+u3XrxrFjx/j5559Zt24dDz74IAMGDOC7774jJCSE1NRU1q5dy7p163j22Wd555132LRpU7W46otNe9TBwcG8+eab7Ny5k507d3LHHXdw7733cuDAAVuGZRYYBYoWHFzp4qtDq1E4k2/gdK7cSUuIZsVRX/tFW6UPpNWZy6oen77aduvgwQcfRKvV8s033/DFF1/w2GOPWZLOli1buPfee3nkkUeIioqibdu2HD58uMbb7tSpE2lpaZw+XfmDZdu2bVZ1fv/9d8LCwpg2bRqxsbGEh4dXm4nu6OiI0Wi85r4SExMpLKw8fv/777+j0Who3759jWO+Gg8PD4KCgvjtt9+syrdu3crNN99sVe+hhx5i0aJFLF26lOXLl3P+/HnAfIvOv/zlL3zwwQds3LiRbdu2kZRUfz+8LmXTHvXQoUOtXr/xxhssXLiQ7du307lzZxtFVc7ZE146Ds4euAAdA9w5cDqPxLQcWnm5XGttIYS4Ydzc3HjooYeYOnUqubm5jBkzxvJeu3btWL58OVu3bsXb25t3332XzMxMq6R0NQMGDKBDhw48+uijzJs3j7y8PKZNm2ZVp127dqSlpREfH0/37t356aefWLFihVWd1q1bc+zYMRITEwkODsbd3b3aaVkjR45k5syZjB49mlmzZnHmzBkmTJjAqFGjLMen68Pf//53Zs6cyU033UR0dDSLFy8mMTGRr7/+GoD33nuPwMBAoqOj0Wg0LFu2jICAALy8vPj8888xGo307NkTV1dX/vOf/+Di4mJ1HLu+2c0xaqPRSHx8PIWFhZc9/gFgMBjIy8uzLPn5DXxZT2cPy1O5QYcQwp498cQTXLhwgQEDBhAaGmopnz59Ot26dWPQoEH069ePgIAAhg0bVuPtajQaVqxYgcFgoEePHjz55JO88cYbVnXuvfdennvuOcaPH090dDRbt25l+vTpVnXuv/9+Bg8ezO23307Lli0ve4qYq6srv/zyC+fPn6d79+488MAD9O/fnwULFtSuMa5h4sSJPP/88zz//PNERESwevVqVq5cSXh4OGD+4fPWW28RGxtL9+7dOX78OKtWrUKj0eDl5cWiRYvo3bs3kZGRrF+/nv/973/4+PjUa4xVKerlDkDcQElJScTFxVFcXIybmxvffPMNd91112Xrzpo1i9mzZ1crT09Pt5roUO+MpSzbk8nfv9tH99beLBvbq+H2JYS44YqLizl27Bht2rTB2dnZ1uGIJuJqf1cnT54kJCSkRvnL5j3qDh06kJiYyPbt23nmmWcYPXo0ycnJl637yiuvkJuba1muVK/elF6Ez4bAm6HE+JuP9ySdyqXUWLtJC0IIIURd2fw8akdHR9q1awdAbGwsCQkJvP/++3z00UfV6jo5OVkd08jLy2vY4BxcID8DSotoXXQAd2cd+cVlpGbm06VV9ZP1hRBCiPpm8x71pVRVxWAw2DqMSmHmYW5N+jaiKu6kJdf9FkIIcYPYNFFPnTqVLVu2cPz4cZKSkpg2bRobN25k5MiRtgzLWsUNOk5so2v5nbQkUQshhLhRbDr0nZWVxahRo8jIyMDT05PIyEhWr17NnXfeacuwrJX3qDm9m249zadl7UmTmd9CCCFuDJsm6k8//dSWu6+ZFm1B7weF2XTTHQPgyJlCci+W4unSMFehEULYRm2vbiXE1dTX35PNJ5PZPUWBsDhI/i+e2QmEtOhG+vmL7DuZw63hLW0dnRCiHjg6OqLRaDh9+jQtW7bE0dFRLhUs6kxVVUpKSjhz5gwajQZHR8fr2p4k6poI7QXJ/4W0bUSH9Cf9/EUS0yRRC9FUaDQa2rRpQ0ZGhtWlMoW4Hq6uroSGhqLRXN90MEnUNRFWPqEsfQdd+7jzv70yoUyIpsbR0ZHQ0FDKysqueU1qIa5Fq9Wi0+nqZWRGEnVN+HcBJw8w5HGLPgMwJ2q5k5YQTYuiKDg4ODTYXZCEqAu7O4/aLmm0EGK+MXh4cRIOWoVzhSWcvHDRxoEJIYRo6iRR11T5+dQOJ7fTKdB8s449MvwthBCigUmirqmKC5+c2mO5k5acTy2EEKKhSaKuqVYx8NjPMD6BaLlCmRBCiBtEJpPVlIOz5Spl0SHeABw4nUdJmQlHnfzeEUII0TAkw9RBax9XvFwdKCkzkZLRwHfwEkII0axJoq6N/Cz46QWUJSPkTlpCCCFuCEnUtaFzgoRP4NDP9PYvAyRRCyGEaFhyjLo2XLyg/wxo0ZaOBMGWC5KohRBCNChJ1LV16xQAIotKgAMcO1vIhcISvPXXd9F1IYQQ4nJk6LuOvFwdaeOrByDxZI5tgxFCCNFkSaKuLVWF47/Bpne4Jcg8IJGYlmPbmIQQQjRZkqhrS1Hgv+Nhw+v01x8HZEKZEEKIhiOJui7KL3wSYUoGYO9J8520hBBCiPomibouyq/73fL8Lhx1GnKKSjl+rsjGQQkhhGiKJFHXRXmPWnN6N9GBzgAkpssNOoQQQtQ/SdR10aIt6P3AWMJd3hmATCgTQgjRMCRR14WiQJh5+LunLhWQCWVCCCEahiTquio/Tt26cC8AyRl5FJcabRmREEKIJkgSdV2VJ2rnzF20dNVSalQ5cFrupCWEEKJ+SaKuq4AIcHRHMeRxj/95QIa/hRBC1D9J1HWl0UJIDwD6uRwBJFELIYSof5Kor0f5hLJOZQcAOUVLCCFE/ZNEfT1CzedT+5zbhaKopJ+/yLkCg42DEkII0ZRIor4erWKgzW1oYsbQ0bfiwic5to1JCCFEkyKJ+no4OMPolXDHNDqHtgQkUQshhKhfdUrU6enpnDx50vJ6x44dTJ48mY8//rjeAmtsokO8ANgjVygTQghRj+qUqP/f//t/bNiwAYDMzEzuvPNOduzYwdSpU5kzZ069BtgoFJ2nj7IPgL3pOZhMcictIYQQ9aNOiXr//v306GE+Nenbb7+lS5cubN26lW+++YbPP/+8PuOzf4YCeKcdrX9+hGCHPPINZRw9W2DrqIQQQjQRdUrUpaWlODk5AbBu3Tr+8pe/ANCxY0cyMjJqvJ25c+fSvXt33N3d8fPzY9iwYaSmptYlJNtxcgO/TuDbnt5+JYAMfwshhKg/dUrUnTt35t///jdbtmxh7dq1DB48GIDTp0/j4+NT4+1s2rSJcePGsX37dtauXUtZWRkDBw6ksLCwLmHZzpPrYHwCHm27AzKhTAghRP3R1WWlt956i/vuu4933nmH0aNHExUVBcDKlSstQ+I1sXr1aqvXixcvxs/Pj127dtG3b9+6hGYbDuZTs7qGegPHJFELIYSoN3VK1P369ePs2bPk5eXh7e1tKX/66adxdXWtczC5ubkAtGjRos7bsKXoID06yjiYmc/FEiMujlpbhySEEKKRq9PQ98WLFzEYDJYkfeLECebPn09qaip+fn51CkRVVaZMmUKfPn3o0qXLZesYDAby8vIsS35+fp321SB+eJbAf3fgbn0qRpPK/tO5to5ICCFEE1CnRH3vvffy5ZdfApCTk0PPnj2ZN28ew4YNY+HChXUKZPz48ezbt48lS5Zcsc7cuXPx9PS0LJ06darTvhqKUlrEIPejAOxJk+t+CyGEuH51StS7d+/m1ltvBeC7777D39+fEydO8OWXX/LBBx/UensTJkxg5cqVbNiwgeDg4CvWe+WVV8jNzbUsycnJdQm/YYTeAkC0mgLIhDIhhBD1o07HqIuKinB3dwdgzZo1DB8+HI1Gwy233MKJEydqvB1VVZkwYQIrVqxg48aNtGnT5qr1nZycLKeFAeTl5dUl/IZRfoOOgPxknCghUU7REkIIUQ/q1KNu164dP/zwA+np6fzyyy8MHDgQgOzsbDw8PGq8nXHjxvHVV1/xzTff4O7uTmZmJpmZmVy8eLEuYdmWz02gb4nGVEKk5iinc4vJziu2dVRCCCEauTol6hkzZvDCCy/QunVrevToQVyc+b7Ma9asoWvXrjXezsKFC8nNzaVfv34EBgZalqVLl9YlLNtSFAg1t8MQ9+MA7JHhbyGEENepTkPfDzzwAH369CEjI8NyDjVA//79ue+++2q8HVVtYtfEDusFKSvp5XAIGExieg6DOgfYOiohhBCNWJ0SNUBAQAABAQGcPHkSRVFo1apVrS520iSV96jbFu9Hg0mOUwshhLhudRr6NplMzJkzB09PT8LCwggNDcXLy4vXXnsNk8lU3zE2HgER4OiOY1kBHZU09p3MwSh30hJCCHEd6tSjnjZtGp9++ilvvvkmvXv3RlVVfv/9d2bNmkVxcTFvvPFGfcfZOGi0ENIDjqynt8Mhkktaczg7n44BNZ9gJ4QQQlRVp0T9xRdf8Mknn1jumgUQFRVFq1atePbZZ5tvogYIi4Mj67nD9QiLSiAxLUcStRBCiDqr09D3+fPn6dixY7Xyjh07cv78+esOqlErP04dYUwGVLnwiRBCiOtSp0QdFRXFggULqpUvWLCAyMjI6w6qUWsVAxoHXMtyCeC8JGohhBDXpU5D32+//TZ3330369atIy4uDkVR2Lp1K+np6axataq+Y2xcHFzgiTWccQ4j853tZGflU2goQ+9U5wn2QgghmrE69ahvu+02Dh06xH333UdOTg7nz59n+PDhHDhwgMWLF9d3jI1Pq274+/gQ5OmMSYV9J+VOWkIIIeqmzt28oKCgapPG9u7dyxdffMFnn3123YE1BdGhXpxOyiQxPYe4m3xsHY4QQohGqE49anENqgq/TGN25jhacoHEdLnlpRBCiLqRRN0QFAWObqRlfgqxmkPsSctpepdLFUIIcUPIDKeGcusUSkrL2LlM5Uy+gYzcYoK8XGwdlRBCiEamVol6+PDhV30/JyfnemJpWrrcjyPQcvMWzmTkkZieI4laCCFErdUqUXt6el7z/UcfffS6AmpqokO9SC5P1HdFBNo6HCGEEI1MrRK1nHpVS6cTedjwA0mKD4lpLWwdjRBCiEZIJpM1pD8+IvLgewzSJpB0KpcyYzO+s5gQQog6kUTdkMLM1/2O0x3iYqmR1Kx8GwckhBCisZFE3ZBCewEQwZ84UsqetBzbxiOEEKLRkUTdkHxuAn1LHCklUjkiN+gQQghRa5KoG5KiWG572UOTKolaCCFErUmibmhh5uHv7pqDHDlTQF5xqY0DEkII0ZhIom5o5T3q7trDKKqJfelyJy0hhBA1J4m6ofl3AUc33Ciio5ImN+gQQghRK5KoG5pWByE9AOgux6mFEELUkiTqGyG04ji1OVHLnbSEEELUlCTqG6H8wifdNQc5W2Dg5IWLNg5ICCFEYyGJ+kZoFQMaB/yVHEKVbPbI8LcQQogakkR9Izi4QLdH2eL3CKWqjkS5QpkQQogaqtXds8R1uOddzuw+SUbaXpn5LYQQosakR30DdQ31BmD/6TxKyuROWkIIIa5NEvUN1Fpfyt0u+3Euy+NgZp6twxFCCNEISKK+gZQv7uFf6j/orTkg51MLIYSoEUnUN1LILeQ4B+NIqUwoE0IIUSM2TdSbN29m6NChBAUFoSgKP/zwgy3DaXiD32TPfRv4r6mPnKIlhBCiRmyaqAsLC4mKimLBggW2DOPG0eqIDvYC4NjZQnKKSmwbjxBCCLtn09OzhgwZwpAhQ2wZwg3nrXekbQsnMs/nkpieQ78OfrYOSQghhB2TY9Q32tb/Y1XxKJ7V/VcmlAkhhLimRnXBE4PBgMFgsLzOz8+3YTR15OyJs6mI7ppUFkqiFkIIcQ2Nqkc9d+5cPD09LUunTp1sHVLtld9JK1o5QnLaGbmTlhBCiKtqVIn6lVdeITc317IkJyfbOqTa87kJVd8SJ6WU0OKDnDhXZOuIhBBC2LFGlaidnJzw8PCwLO7u7rYOqfYUBSX0FgB6lN+fWgghhLgSmybqgoICEhMTSUxMBODYsWMkJiaSlpZmy7AaXvnwd6wmlT1pcoMOIYQQV2bTRL1z5066du1K165dAZgyZQpdu3ZlxowZtgyr4YXFARCrOcS+tHM2DkYIIYQ9s+ms7379+jXPyVT+EZgc9HiUFlKWmUxxaR+cHbS2jkoIIYQdalTHqJsMrQ4ltCcAXUkhOUPupCWEEOLyJFHbiFJ+nLqHJlVu0CGEEOKKJFHbSvlx6u6agyTKhDIhhBBXIInaVlrFYNI44K/kkJ120NbRCCGEsFOSqG3FwQVTYFeMqoJH3iHOFRiuvY4QQohmRxK1DemG/5th7t+wxtRdLnwihBDisiRR25LPTbQPbQUgiVoIIcRlSaK2sehQL0AStRBCiMuTRG1j/XNXsNxxJi3S12AyNcOLvwghhLgqSdQ2FlCaRozmMFFl+zl6ttDW4QghhLAzNr2EqABN9EgWHPbkm6zWeKTn0M7PzdYhCSGEsCPSo7a14Bhy2/+V0/iSmC4XPhFCCGFNErUdiA7xBmRCmRBCiOokUduBGI8LPKH9iXZZq7lYYrR1OEIIIeyIJGo74H8ugekOXzNCs479p3NtHY4QQgg7IonaDihh5jtpRStH2Hc828bRCCGEsCeSqO2BTzuKHFrgpJSS8+cfto5GCCGEHZFEbQ8UhYuB3QFwzdxh42CEEELYE0nUdsItvC8AHQz7yc4vtnE0Qggh7IUkajvhdFNvAGI1h9h9/KyNoxFCCGEvJFHbC/8IDBoXPJQi/hX/P8Z9vZtNh85glOt/CyFEsyaXELUXWh1lrXrglL6Jt7Uf8kfKr/ycHMqXruF06d6XB2JbE9LC1dZRCiGEuMEkUdsRfdQwSN/EzZo0btakmQtLofOvn/LBhmP0aefLuJA0YkL0OIT2BL2PTeMVQgjR8CRR25PYxyG0F2TshawkjBlJ5OZcIFofzO9/nmPL4bOMOzEPB00KP7R+lY6D/0bHAA84dwRObIWALtCyIzi42PqTCCGEqCeSqO2NX0fzwkNogRbA10D6+SKW7Uzn1PYwUsoK+HeqGwcPbiEq2JNXW26he8qb5vUVLfi0Mydt/y4QEAH+ncE9EBTFdp9LCCFEnUiibiRCWrgyZWAHjAPi2Xz4DG0S0jmSksXek7l8frqIMofOROpOojfmwtlU87J/eeUGXFqUJ+8I82NglDmBCyGEsGuSqBsZrUbh9g5+3N7Bj7MFBlbsPsXSnW6MyL4FDCr+XOAOryzuDcoh2iEd53MpcO4wXDwPxzabF4CQW+CJXyo3vHMxeIVCWG9wcLbNhxNCCFGNJOpGzNfNiaf6tuXJW9uwOy2HpQlp/LhPx5KcFizJAa2mF3d09GNE35b09T6L7kwyZO2HzP0Q0r1yQyWF8ONzgAovHK5M1Ce2QlkxBHUFF29bfEQhhGj2JFE3AYqiEBPmTUyYNzOGduanfadZmpDO7rQc1iZnsTY5Cz93Jx6I6c6D3YfT2ldvvQFDPnS6F/Izwc2vsvy39+DwGvNzn3bQKqZy8e8iPW8hhLgBFFVVG+0VNU6ePElISAjp6ekEBwfbOhy7czgrn6UJ6Xy/5xTnC0ss5T3btODhHiEM6RKIs4P2yhv46QX4cx1cOFb9PY2D+Vh3qxhoFWt+9GkHGrmGTp2VXoSzhyA7BbKTIT8LWrQtn2DYCbzbgFZ+W4smqvAcnN4NhWfMS0E2FJ6Fwmzz64s50KINhPQ0H7oLjgUXL1tHXWe1yV+SqJuBkjIT61OyiE9IZ/PhM1T8i7s767g3OoiHYkPp0soD5UqzwovOw6ndcGoXnNppfiw6V72ekwcMfhO6jjS/VlWZaX4luSfh5E5zQs5ONifn80dBNV15ncBo+NumytfHtoBnMHiFyQ+k+mYyQkmB+W+4EScDm1BVKM4tT7JnzIn2Yg7EjK6s88s0OLQabp8KXe43lx1aA9/8tRY7Usynoz65Dpzc6vMT3BC1yV/y87wZcNRpGBIRyJCIQE7nXOS7XSf5dmc6Jy9c5KvtaXy1PY2bAz14uHsIw6Jb4enqYL0B1xYQPsC8AKgq6oXjlKbvRD25C+X0bnRZe9EY8jhe7MrZ4+cpLjXhfuIX2u+aw8nAQSR0eIHiUiOGMlO1R0OpkeIyI4ZSk+XRy9WB9v7udAhwp72/O21b6nHSXaX3b8/+XAeZSRD1/8Dd31y25yvYOLd6XRdv8OsMfjeDe4A5eWcnw5lU84hFBZMRvn7APIdgwm7wuclcnp4AxTnm9T1aNa4fSsYy85d6Xgbkny5/zDCPNJjKwFRqfuw6CkJvMa9zahdsesfc0xpcpT2XjDCvaywrX7diMVZux/K6DIylMGAW9Bpfvt3d8OkA84+gyfsqt/vHR1BmgJYdzItnaPP7kZSXAcc2Ven5nqlMyBXJ2VhSfb2oEaBzND8vyIZzf0Luqcr3PYLMp5Pq/UDfEvS+5kNx+pbmxcnD/P9C+g5I327+f6O00DpJf/8386G82/5unlvTREiibmaCvFyY2D+c8be3Y9vRc8QnpPPL/kxSMvKYufIAb6xKoWebFgBWCbW41IShrPLRUGZCVV2BW4Fb0WKkvXKSE/81UcQ2AF7Q/UKULpPdh04wNTkJAB1lrHCcQYopjL3qTewz3USqGkLZZf4U16VkW57rNAptfPW0D3Cng7+7JYmHtnBFq7GDZFRwprJnbMiD216sfG/NDMg+YB6+dh9kLguMMh8u8LvZXF7x6OZ/+eRqMpl7eBUuXgCfcMhNA+/WleV//Bv2f2d+7uRhTiZ+N0PLm8v3cfOV99GQSoogJ808YuDfyVymqvDtKPPoQl6G+Yv+aiMKFULjKhN14Tk49LN5tKGqrP3m/dWGqbTyuab8R6HJaF1nx8fmBFNB5wK+4ZWJu2VH8O1g/uGgveQHrz1TVXOSzTtpneBWT4WDP5p/xHQZbi7LOgAr/nbtbTq6g1vLykRbdrEyUfeeaO5h+4RX1g/oAmN/u/o2Q3tC7GPm5wVnIDe98j2Tyfy3UJxrTtQVDv1iPtslpKd5qfix3IjI0Lcgp6iEH/acIj4hnYOZ+bVeX1HAWafF2UGDU5VHL52BjuoxyhzcyNa3x0mn4aayP3nu6FNW65dpnDjv3pEc7wjyfCIp9I3mhNqS1KxCDmXlczAzn/zissvu20mnIdzfjfb+7nQMqEzgAR7OVx7Kvx7FeXDmoPnLquJYcnYKFFW545nOGaaervyyXzfbnDR6/g1CetRvPCaTdY9u7QzzF9O5P809xctx8S5P3OXHvkPjUP07k28o43xBCecKSzhfWML5QgOqCj5uTvi4OeKrNz+6Omor29ZYCgVZl/SCyx+7P1GZUJO+g+VPmE//e2xVZSz/7AAFmZWvFa15JME9EDwCzY+ObqDRmRetDsIHmnteYE7yf64397463l25nSMbzL06jdY8n6Lq+porLM6elb0zk8mcuBWt9byAzf80/9ufPWReLtdzBPM+fW4yJ+/uT0Kbvtf+t2xoJYVw4QRcOA455Y9VX5cWAQq8mgU6J/M6K56Bvd/AHa9C3/LkdyYVfn7xCj1f3/Jy3xt/hUSTyXxoLv0P6Dm28ofSf8fDnv9U1vNuXZ60e5iPdfvdXPn/6g3UqI5Rf/jhh7zzzjtkZGTQuXNn5s+fz6233lqjdSVR1y9VVdl/Ko/kjFwcdRqcdVqcHCofnaySceV7Dlql5kmxOA9O/F5+vLt8Kc69fF2NA+icUXVOZD2ewMFzZRzKyics6f8IvrCDT0r6s6LEnAhClCzGaf9LCQ4YcEDVOeGhd8PTw40WHu74enni38ITN72rOZHqnMyPrWIrZ69fvABlJeDkDo7lN0A5dwR2f1GelFOsf8FbUcy9KL9O5qXPc5XbsAFTqYH8Uwe5eGo/ZVkp6M4exDXnEG5F6Wiw7rX+R3MvrxlGUGI04UU+k3Tfc1ANZanxdkud+zRbaKWcJUA5T5A2hyBNDn6cx0vNQcPlv0Ly+r+FS6+ncdBq4PjvED8CgnvAI99VVjrwA2gdy5NykPkL3gZfmnViLDMnuDOp5h9vZw+ZH88cMg/JVnhgcWVv9M915kma7QfBkLcq65RevP7EZiw/PFCxnbOHzYdXLpwwx1l45hobUMzDz0+sMc99APOpnIZ88w8O1xbXF5+tpK6Gw7+Yh8yzDsClf6+O7uaJaSE9zT32VrHg7NHgYTWaY9RLly5l8uTJfPjhh/Tu3ZuPPvqIIUOGkJycTGhoqC1Da5YURSEi2JOIYM+G24mzB3QYYl7A/Cv4/FHrxJ25z9xTMZVCSSlKST4B3h4E+Oro18EPsnLhzAHmDRnFpPB+pGblk5+6hQf2bbTeV2H5knHlcPY/tJ3WbcNxc9LBxrfgj4XQZwoMmGmuUHQefn/feiWPVpXDyBXD1r4dGjQxlxpNXCis7O2eKyyp8tpgLiuo6AmXcKGoBPMdUr2AuPIFnCjhJuU07ZWTtNecpL2SzpaStpSYzMk70uEUj2l/IUMTQFbIg2gUhXOFJUw9s5SWnK8MqMp3XamqJQtvslRvMlVvslVvMtUWbF5lIuWnn/F0ccBH74Cv11J8FUd8ftiPj5sjPm5O+Op74uPqhI+DI75aJzwUDXZwIKNmtDpzr9nnJuh4V2W5yQR5p8xXBzyTCsFVrlmQnWI+iyI/07r+2zeVj3S0Lx8+L3+smiArhqcresOd7q3sNa6eaj7sccercOuU8u2WWV+dEMDZC7zDzL1Kr/JH7zDwag1eIZU96QoBXa67mWyuw2DzAuZOwcmd5ce5/zA/L8mHoxvMCwCKefTgjmnmlxV9WRvO97Bpj7pnz55069aNhQsXWspuvvlmhg0bxty5l5locwnpUTdRxlJzz7usuHwxVB7XBPNEn9x087ncFZOoctJh31IwllBWcpG8/AJyCwooLCykqKgQQ3ERxhIDTpTipJTgRCmOlPFAyUxycSPY24XZus+5I38lqR2fxdj3JZx0GkzF+fhsf5NCr3AKPduT5xFOic6dMqNKqdFEmUk1L0aTucxkfrSUmcrrXa2sfJ1SowmjSaW0vF5xqZELRaWcKzCQd4Wh/2txd9bho3ekhd6RFnon83M3xypljvjonfDWO+Cjd8Il90/zMKGjG/R7uXJDP78EJQWUugaQ79iSC1pfziotyFC9OFXixrnCMs4VGjhXUMLZAgNnC8w/IGp7O3WdRjEn8fJhdh+9Iy6OOhy1CjqtBp1WwUFT/qjV4KBV0GnKH7UadBoFR50GnaWOYnnuqNVY6jhU2ZaDrvo2HLSahpn7UHTefPzcQQ/BMeaynHSYf5WEqG9pvgRw7knrnvrEPebT9wA2/AM2vQUxj8HQ+eay0ouwY5F1YrbhDHZVVTGpYDSp5kU1P5rKn1c8lhlVTBXvqSpGE1Wem+uoVcpVtXJbqlpZt2Ldyufm/Vv2p6qoxjI88v/E90IifjmJ+OXsxaP4FL+2n8EB/79gVFV885IZljKFo169+KntNAZ1DqBb6PVfAKpRDH2XlJTg6urKsmXLuO+++yzlkyZNIjExkU2bNlVbx2AwYDAYLK9PnTpFp06dJFGLGik0lHE4u4BDmfmkZuVzKCuf1Mx8svMNVWqpKKio2N9MXkUBb9eqCdb6sYWbk1WZl6sjjjrbfQ6TSSXnovmHxtmCEksiP1dg4Gyh+fFc+THxswWGK85DsBWNgiVxV6Tsii/Lqt+aapXhBevyS59cua47BbRTTnMTJ2mnnKKd5hThyilaKVXmPgAmVSELb9LxZ47pcY4QikYBHyUPB8XIWbxQNFoUQKOYD0kpivmzKCjmx/Iyc7lirgflZYqlbtXXGkW5JHleknQvSbYVCbjskvqNQUsuUIwT+ZhHyEZrf2G2wxdsMEbxWOlLvDasC6NuCbvu/TSKoe+zZ89iNBrx97eegefv709mZuZl15k7dy6zZ8++EeGJJkjvpCM6xIvoEC+r8guFJeakXZ64D2Xlc+RMIUaTaumRaTXKZXtcVXtsly3TaNBqFRw01j3CmmzPSafB29URHzdzb9jTxcE+ZrjXkEajWH5UhNdgoq2hzGgZwj9rSeIGLpaYKDOZKDVWjkiUGE1VRjHM5aWWUQ7rupby8jpVRzAqXpcaq2cRk2q+BsEVpovVqwvoSSCcBMKtyl0p5iblNJ5KIadUX06pvpRQdTa5eVZ6IRVXGzSVL42PRjHfy0CjKGg1ClpFQaNRqpRRrazqOhpFQVOljkap2AaWbVZdRyl/3/wcyz4VJdi8r/I6GnU0n17sCRotT7q34eYA9xveNjY/PevSSUiqql5xYtIrr7zClClTLK8retRCXA9vvSM92/rQs62PrUNp1px0WgI9XQj0vPH3U1fLe31VD0uUGk2WHwFKlSPnl/t6qlpW9ftLudz7V9iWUu1JZV0VlfL/zEO2auWj5TlVyypfm0zm9a9W11T18XJ1TapVMquaLHVWydScUKsmRq3GXEdzybraKom1Iinarxib7t1midrX1xetVlut95ydnV2tl13ByckJJ6fKyQ55eXkNGqMQonlQFAWdVkGn5eqX1RXCBmx2AMvR0ZGYmBjWrl1rVb527Vp69eplo6iEEEII+2LToe8pU6YwatQoYmNjiYuL4+OPPyYtLY2xY8faMiwhhBDCbtg0UT/00EOcO3eOOXPmkJGRQZcuXVi1ahVhYdc/o04IIYRoCmw+mezZZ5/l2WeftXUYQgghhF2yv5NFhRBCCGFh8x719TCVX/YwI+Mq14gUQggh7ExF3qrIY1fTqBN1VlYWAD161PMdiYQQQogbICsr65r3trD53bOuR1lZGXv27MHf3x9NPdy8PT8/n06dOpGcnIy7+42/+kxjJe1Wd9J2dSPtVnfSdnVT3+1mMpnIysqia9eu6HRX7zM36kRd3/Ly8vD09CQ3NxcPj4a/zVlTIe1Wd9J2dSPtVnfSdnVjy3aTyWRCCCGEHZNELYQQQtgxSdRVODk5MXPmTKvriYtrk3arO2m7upF2qztpu7qxZbvJMWohhBDCjkmPWgghhLBjkqiFEEIIOyaJWgghhLBjkqjLffjhh7Rp0wZnZ2diYmLYsmWLrUOye5s3b2bo0KEEBQWhKAo//PCDrUNqFObOnUv37t1xd3fHz8+PYcOGkZqaauuwGoWFCxcSGRmJh4cHHh4exMXF8fPPP9s6rEZn7ty5KIrC5MmTbR2K3Zs1axaKolgtAQEBNzQGSdTA0qVLmTx5MtOmTWPPnj3ceuutDBkyhLS0NFuHZtcKCwuJiopiwYIFtg6lUdm0aRPjxo1j+/btrF27lrKyMgYOHEhhYaGtQ7N7wcHBvPnmm+zcuZOdO3dyxx13cO+993LgwAFbh9ZoJCQk8PHHHxMZGWnrUBqNzp07k5GRYVmSkpJubACqUHv06KGOHTvWqqxjx47qyy+/bKOIGh9AXbFiha3DaJSys7NVQN20aZOtQ2mUvL291U8++cTWYTQK+fn5anh4uLp27Vr1tttuUydNmmTrkOzezJkz1aioKJvG0Ox71CUlJezatYuBAwdalQ8cOJCtW7faKCrRnOTm5gLQokULG0fSuBiNRuLj4yksLCQuLs7W4TQK48aN4+6772bAgAG2DqVROXz4MEFBQbRp04aHH36Yo0eP3tD9N+q7Z9WHs2fPYjQa8ff3tyr39/cnMzPTRlGJ5kJVVaZMmUKfPn3o0qWLrcNpFJKSkoiLi6O4uBg3NzdWrFhBp06dbB2W3YuPj2f37t0kJCTYOpRGpWfPnnz55Ze0b9+erKwsXn/9dXr16sWBAwfw8fG5ITE0+0RdQVEUq9eqqlYrE6K+jR8/nn379vHbb7/ZOpRGo0OHDiQmJpKTk8Py5csZPXo0mzZtkmR9Fenp6UyaNIk1a9bg7Oxs63AalSFDhlieR0REEBcXx0033cQXX3zBlClTbkgMzT5R+/r6otVqq/Wes7Ozq/WyhahPEyZMYOXKlWzevJng4GBbh9NoODo60q5dOwBiY2NJSEjg/fff56OPPrJxZPZr165dZGdnExMTYykzGo1s3ryZBQsWYDAY0Gq1Noyw8dDr9URERHD48OEbts9mf4za0dGRmJgY1q5da1W+du1aevXqZaOoRFOmqirjx4/n+++/59dff6VNmza2DqlRU1UVg8Fg6zDsWv/+/UlKSiIxMdGyxMbGMnLkSBITEyVJ14LBYCAlJYXAwMAbts9m36MGmDJlCqNGjSI2Npa4uDg+/vhj0tLSGDt2rK1Ds2sFBQX8+eefltfHjh0jMTGRFi1aEBoaasPI7Nu4ceP45ptv+O9//4u7u7tlNMfT0xMXFxcbR2ffpk6dypAhQwgJCSE/P5/4+Hg2btzI6tWrbR2aXXN3d682B0Kv1+Pj4yNzI67hhRdeYOjQoYSGhpKdnc3rr79OXl4eo0ePvmExSKIGHnroIc6dO8ecOXPIyMigS5curFq1irCwMFuHZtd27tzJ7bffbnldcbxm9OjRfP755zaKyv4tXLgQgH79+lmVL168mDFjxtz4gBqRrKwsRo0aRUZGBp6enkRGRrJ69WruvPNOW4cmmqiTJ08yYsQIzp49S8uWLbnlllvYvn37Dc0PcvcsIYQQwo41+2PUQgghhD2TRC2EEELYMUnUQgghhB2TRC2EEELYMUnUQgghhB2TRC2EEELYMUnUQgghhB2TRC2EEELYMUnUQojrpigKP/zwg63DEKJJkkQtRCM3ZswYFEWptgwePNjWoQkh6oFc61uIJmDw4MEsXrzYqszJyclG0Qgh6pP0qIVoApycnAgICLBavL29AfOw9MKFCxkyZAguLi60adOGZcuWWa2flJTEHXfcgYuLCz4+Pjz99NMUFBRY1fnss8/o3LkzTk5OBAYGMn78eKv3z549y3333Yerqyvh4eGsXLnS8t6FCxcYOXIkLVu2xMXFhfDw8Go/LIQQlyeJWohmYPr06dx///3s3buXRx55hBEjRpCSkgJAUVERgwcPxtvbm4SEBJYtW8a6deusEvHChQsZN24cTz/9NElJSaxcuZJ27dpZ7WP27Nk8+OCD7Nu3j7vuuouRI0dy/vx5y/6Tk5P5+eefSUlJYeHChfj6+t64BhCiMVOFEI3a6NGjVa1Wq+r1eqtlzpw5qqqqKqCOHTvWap2ePXuqzzzzjKqqqvrxxx+r3t7eakFBgeX9n376SdVoNGpmZqaqqqoaFBSkTps27YoxAOqrr75qeV1QUKAqiqL+/PPPqqqq6tChQ9XHHnusfj6wEM2MHKMWogm4/fbbLfe5rtCiRQvL87i4OKv34uLiSExMBCAlJYWoqCj0er3l/d69e2MymUhNTUVRFE6fPk3//v2vGkNkZKTluV6vx93dnezsbACeeeYZ7r//fnbv3s3AgQMZNmwYvXr1qtNnFaK5kUQtRBOg1+urDUVfi6IoAKiqanl+uTouLi412p6Dg0O1dU0mEwBDhgzhxIkT/PTTT6xbt47+/fszbtw4/vnPf9YqZiGaIzlGLUQzsH379mqvO3bsCECnTp1ITEyksLDQ8v7vv/+ORqOhffv2uLu707p1a9avX39dMbRs2ZIxY8bw1VdfMX/+fD7++OPr2p4QzYX0qIVoAgwGA5mZmVZlOp3OMmFr2bJlxMbG0qdPH77++mt27NjBp59+CsDIkSOZOXMmo0ePZtasWZw5c4YJEyYwatQo/P39AZg1axZjx47Fz8+PIUOGkJ+fz++//86ECRNqFN+MGTOIiYmhc+fOGAwGfvzxR26++eZ6bAEhmi5J1EI0AatXryYwMNCqrEOHDhw8eBAwz8iOj4/n2WefJSAggK+//ppOnToB4Orqyi+//MKkSZPo3r07rq6u3H///bz77ruWbY0ePZri4mLee+89XnjhBXx9fXnggQdqHJ+joyOvvPIKx48fx8XFhVtvvZX4+Ph6+ORCNH2KqqqqrYMQQjQcRVFYsWIFw4YNs3UoQog6kGPUQgghhB2TRC2EEELYMTlGLUQTJ0e3hGjcpEcthBBC2DFJ1EIIIYQdk0QthBBC2DFJ1EIIIYQdk0QthBBC2DFJ1EIIIYQdk0QthBBC2DFJ1EIIIYQdk0QthBBC2LH/D6V6eLDipFlSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_values\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa074723-e3f7-4f7e-a267-855531a037dc",
   "metadata": {
    "id": "aa074723-e3f7-4f7e-a267-855531a037dc"
   },
   "source": [
    "- Note that we previously calculated the accuracy values on 5 batches only via the `eval_iter=5` setting; below, we calculate the accuracies on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1D2awlEq0gZi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1D2awlEq0gZi",
    "outputId": "d603eda1-d912-43eb-ec9c-af6a622510a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.90%\n",
      "Validation accuracy: 96.64%\n",
      "Test accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d",
   "metadata": {
    "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d"
   },
   "source": [
    "- As we can see based on the relatively high accuracy values above, the LoRA finetuning was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65b45107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9108e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
